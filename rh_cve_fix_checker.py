#!/usr/bin/env python3

import re
import grequests
import argparse
import json
import csv
from sys import stdout, stderr, exit
from tabulate import tabulate


pyxis = "https://catalog.redhat.com/api/containers"
hydra = "https://access.redhat.com/hydra/rest/securitydata"




def main():
    parser = argparse.ArgumentParser(description="A tool to identify what CVE's have been fixed in images in Red Hat's container image registries")
    parser.add_argument("registry", help="the Red Hat registry, access is for Red Hat images, connect is for partners", choices=["registry.access.redhat.com","registry.connect.redhat.com"])
    parser.add_argument("repository", help="the repo for the image, this is can be a single image name or a path ex: (ubi8 or ubi8/ubi)")
    parser.add_argument("-o", "--output", choices=["csv", "table", "json"], help="output format", default="json")
    parser.add_argument("--since", help="this is an image tag and only this image and newer will be returned, if invalid nothing will be returned")
    parser.add_argument("--arch", help="only look at specific architecture", choices=["amd64", "aarch64", "s390x", "ppc64le"])
    parser.add_argument("-e","--show-existing-cve", action='store_true', help="Shows any known CVEs existing in each image")
    parser.add_argument("--cves", nargs="*", help="a space separated list of only the cves of interest, only images that fix these cves will be shown, does not take into account rollup patching")
    args = parser.parse_args()
    
    
    validate_cve_list(args.cves)


    images = image_lookup(args.registry, args.repository, since=args.since, arch=args.arch, show_existing=args.show_existing_cve)

    if args.cves is not None:
        images = extract_cves(images, args.cves)
            

    print_output(images, args.output)


def validate_cve_list(cves):
    if cves is None:
        return
    failed = []
    cve_reg = re.compile(r'CVE-\d{4}-\d{4,7}')
    for cve in cves:
        if not cve_reg.fullmatch(cve):
            failed.append(cve)
    if len(failed) > 0:
        for failure in failed:
            print(f"Invalid CVE pattern detected: {failure}", file=stderr)
        exit(3)


def extract_cves(images, cves):
    # convert cves to a set so we can use intersection
    cves = set(cves)
    def check_images():
        for image in images:
            if len(cves.intersection(set(image["fixed_cves"]))) > 0:
                yield image

    return [ i for i in check_images() ]


    
def print_output(images, output):
    if output == "csv":
        csv_keys = images[0].keys()
        writer = csv.DictWriter(stdout, fieldnames=csv_keys)
        writer.writerows(images)
    elif output == "table":
        print(tabulate(images))
    else:
        print(json.dumps(images))

def image_lookup(image_registry,image_repo, since=None, arch=None, show_existing=False):


    #image_registry = "registry.access.redhat.com"
    #image_repo = "ubi8"
    pyxis_image_url = f"{pyxis}/v1/repositories/registry/{image_registry}/repository/{image_repo}/images"

    imagedata = pyxis_calls(pyxis_image_url)

    advisory_set = set()
    return_list = []
    seen = False
    for image in imagedata: 
        image_advisory_id = []
        image_tags = []
        content_advisory_ids = []
        if (arch is not None) and (image["architecture"] != arch):
            continue
        for repository in image["repositories"]:
            if "image_advisory_id" in repository.keys():
                image_advisory_id.append(repository["image_advisory_id"])
            if "content_advisory_ids" in repository.keys():
                content_advisory_ids += repository["content_advisory_ids"]
            for tags in repository["tags"]:
                if tags["name"] == "latest":
                    continue
                if (not seen) and (since is not None) and tags["name"] == since:
                    seen = True
                image_tags.append(tags["name"])

        
        # This makes the assumption that the api returns oldest to newest
        # Logic for "since"
        if (not seen) and (since is not None):
            continue

        this_image = {
            "image": f"{image_registry}/{image_repo}",
            "tag": max(set(image_tags), key=len),
            "architecture": image["architecture"],
            "image_advisory": list(set(image_advisory_id)),
            "content_advisory": list(set(content_advisory_ids)),
            "fixed_cves": [],
        }
        if show_existing:
            this_image["existing_cves"] = list(get_existing_cves(image["_links"]["vulnerabilities"]["href"]))
            
        advisory_set.update(this_image["content_advisory"])
        advisory_set.update(this_image["image_advisory"])
        return_list.append(this_image)

    # Only need to look at RHSA
    # Per Red Hat CVEs are not included in RHBA or RHEA
    # https://access.redhat.com/articles/explaining_redhat_errata
    advisory_list = list(filter(lambda advisory: "RHSA" in advisory, advisory_set))
    hydra_responses = list(map(lambda hydra_response: hydra_response.json(), grequests.map((grequests.get(f"{hydra}/csaf/{advisory}.json") for advisory in advisory_list))))
    advisory_dict = {}

    for i in range(len(advisory_list)):
        advisory_dict[advisory_list[i]] = hydra_responses[i]

    for this_image in return_list:
        for advisory in (this_image["content_advisory"] + this_image["image_advisory"]):
            this_image["fixed_cves"] += list(get_fixed_cves(advisory_dict.get(advisory)))

    return return_list

def get_fixed_cves(hydra_response):
    if hydra_response is not None and "vulnerabilities" in hydra_response.keys():
        for vuln in hydra_response["vulnerabilities"]:
            yield vuln["cve"]

def get_existing_cves(link):
    data = pyxis_calls(f"{pyxis}{link}")
    for cve in data: 
        yield cve['cve_id']


def pyxis_calls(pyxis_url):
    count = 0
    data = []

    # Get the first Pyxis request, which includes page size and total number of entries
    pyxis_response = grequests.map([grequests.get(f"{pyxis_url}")])[0].json()
    if pyxis_response["total"] == 0:
        return data
    data += pyxis_response["data"]
    count += len(pyxis_response["data"])
    total = pyxis_response["total"]

    # Submit subsequent Pyxis requests, starting from page 1 (since page 0 was fetched above)
    total_pages = (total + count - 1) // count
    pyxis_responses = map(lambda response: response.json(), grequests.map(map(lambda page: grequests.get(f"{pyxis_url}?page={page}"), range(1, total_pages))))
    for pyxis_response in pyxis_responses:
        data += pyxis_response["data"]
        count += len(pyxis_response["data"])
    return data


if __name__ == "__main__":
    main()
